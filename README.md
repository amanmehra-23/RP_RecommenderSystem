# Research Paper Recommender System

A **contentâ€‘based** document recommender that uses:

1. **BM25** for fast lexical candidate retrieval  
2. **SBERT** (`allâ€‘mpnetâ€‘baseâ€‘v2`) for semantic embeddings  
3. **FAISS** (innerâ€‘product on L2â€‘normalized vectors) for ANN lookup  
4. A simple **Streamlit** UI to query by terms/title/abstract  

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ data/
â”‚   â””â”€â”€ arvix_data.csv         # raw CSV with columns: terms, titles, abstracts
â”œâ”€â”€ models/                      # artifacts from GPUâ€encode pipeline
â”‚   â”œâ”€â”€ bm25.pkl                 # pickled BM25 index
â”‚   â”œâ”€â”€ dataset.pkl              # pickled DataFrame (terms, titles, abstracts)
â”‚   â”œâ”€â”€ embeddings.npy           # normalized SBERT embeddings
â”‚   â””â”€â”€ faiss_index.bin          # FAISS IndexFlatIP
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ train_embeddings.ipynb   # Jupyter notebook to build indices
â”œâ”€â”€ app.py                       # Streamlit web app
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ README.md                    # this file
```

---

## ğŸ› ï¸ Prerequisites

- **macOS** or **Linux**  
- PythonÂ 3.11 (on macOS) or 3.10/3.11 (Linux)  
- Xcode Commandâ€‘Line Tools (macOS):  
  ```bash
  xcode-select --install
  ```
- (Optional, recommended) [Watchdog](https://pypi.org/project/watchdog/) for Streamlit file watching:
  ```bash
  pip install watchdog
  ```

---

## ğŸš€ Setup

1. **Clone** this repo:
   ```bash
   git clone https://github.com/yourusername/ResearchPaperRecommenderSystem.git
   cd ResearchPaperRecommenderSystem
   ```

2. **Create & activate** a PythonÂ 3.11 venv:
   ```bash
   python3.11 -m venv .venv
   source .venv/bin/activate
   ```

3. **Install** dependencies:
   ```bash
   pip install --upgrade pip
   pip install -r requirements.txt
   ```

---

## âš™ï¸ Training / Indexing

### GPUâ€accelerated embedding (Colab recommended)

If you have a GPU (e.g. on Colab):

```bash
python train_embeddings_gpu.py
```

This will:

- Build a **BM25** index (`bm25.pkl`)  
- Compute & normalize **SBERT** embeddings (`embeddings.npy`)  
- Build a **FAISS** innerâ€‘product index (`faiss_index.bin`)  
- Save a minimal DataFrame (`dataset.pkl`)

### CPU fallback

If you cannot run GPU code locally, use:

```bash
python train_embeddings.py
```

---

## ğŸ“Š Offline Evaluation

To measure P@5, R@5, nDCG@5 on the first 100 docs (using BM25 topâ€‘5 as pseudo groundâ€‘truth):

```bash
python evaluate.py
```

You should see output like:

```
Offline evaluation (first 100 docs):
P@5       0.60
R@5       0.60
nDCG@5    0.90
```

---

## ğŸŒ Running the Streamlit App

```bash
streamlit run app.py
```

Then open your browser at [http://localhost:8501](http://localhost:8501).

### Known Issue on macOS

Due to a Streamlit fileâ€‘watcher bug crashing on PyTorchâ€™s MPS backend:

- We **disable** the watcher and force **CPU** inference in `app.py`.  
- If you still see a **segmentation fault**, you can:
  1. **Disable dev mode**:  
     ```bash
     streamlit run app.py --global.developmentMode=false
     ```
  2. **Run on Linux** or in a **Docker** container.  
  3. **Use Jupyter** to call `model.encode()` and FAISS directly as a fallback UI.

---

## ğŸ”­ Next Steps

- Fineâ€‘tune a **crossâ€‘encoder** for better ranking.  
- Add **MMR** diversification or a twoâ€‘stage BM25â€¯â†’â€¯semantic pipeline.  
- Collect **user feedback** for collaborative filtering.  
- Deploy via **Docker** or **Streamlit Cloud** for production.

---

